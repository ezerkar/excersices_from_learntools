{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will be introduced to two datasets, with similar tasks for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('../input/data1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data1 includes features of house sales, your mission is to predict the selling price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 - for the prediction, do you need a classifier or a regressor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 - choose a prediction model and initilize it (don't forget to import it)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 - in order to have testable results we need a test set, create one (import tools if you need them):\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4 - look at the data and find the prediction target, create a feature df as well:\n",
    "y_train = train['SalePrice']\n",
    "y_test = test['SalePrice']\n",
    "X_train = train[[x for x in data1.columns if x!='SalesPrice']]\n",
    "X_test = test[[x for x in data1.columns if x!='SalesPrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 - fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6 - predict using the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167000</td>\n",
       "      <td>167255.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169500</td>\n",
       "      <td>169573.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191000</td>\n",
       "      <td>190967.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141000</td>\n",
       "      <td>141136.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>234000</td>\n",
       "      <td>233156.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>135000</td>\n",
       "      <td>134994.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>139000</td>\n",
       "      <td>138943.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>156500</td>\n",
       "      <td>156775.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>142500</td>\n",
       "      <td>142514.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>320000</td>\n",
       "      <td>319448.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       real    predict\n",
       "0    167000  167255.20\n",
       "1    169500  169573.40\n",
       "2    191000  190967.80\n",
       "3    141000  141136.00\n",
       "4    234000  233156.84\n",
       "..      ...        ...\n",
       "360  135000  134994.32\n",
       "361  139000  138943.36\n",
       "362  156500  156775.40\n",
       "363  142500  142514.53\n",
       "364  320000  319448.05\n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7 - compare real and predict by showing it out and looking at it\n",
    "real_and_predict = pd.DataFrame(zip(y_test.values, y_pred), columns = ['real', 'predict'])\n",
    "real_and_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.78213698630134"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8 - define a metric and grade your model\n",
    "def metric1(real_and_predict):\n",
    "    return np.mean(abs(real_and_predict['real'] - real_and_predict['predict']))\n",
    "metric1(real_and_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018.9066776737793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metric1(real_and_predict):\n",
    "    return np.sqrt(np.square((real_and_predict['real'] - real_and_predict['predict'])).mean())\n",
    "metric1(real_and_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46363698603176823"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9 - define a diffrent metric and grade your model\n",
    "def metric2(real_and_predict):\n",
    "    sq = np.square((real_and_predict['real'] - real_and_predict['predict']) / real_and_predict['real']).mean()\n",
    "    return np.sqrt(sq)*100\n",
    "metric2(real_and_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10 - do you think one of the metrices is better than the other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11 - try to build a better model (any way you want diffrent algo, diffrent parameters or diffrent features)\n",
    "model2 = RandomForestRegressor(n_estimators=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43991836283423047"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q12 - choose one of the metrices and check if indeed the new model is better\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred_2 = model2.predict(X_test)\n",
    "real_and_predict_2 = pd.DataFrame(zip(y_test.values, y_pred_2), columns = ['real', 'predict'])\n",
    "metric2(real_and_predict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4154515511707174 0.445976810707069\n",
      "0.4386976680373751 0.413906526864964\n",
      "0.42128675150730877 0.4102874187857231\n",
      "0.4340390672484816 0.44373398008697085\n",
      "0.3902683798761668 0.4524355407466248\n"
     ]
    }
   ],
   "source": [
    "#Q13 - in case your models are not deterministic (well at least one of your models),\n",
    "#      run the comparison between them 5 times to see if the better one is always better\n",
    "for i in range(5):\n",
    "    model2.fit(X_train, y_train)\n",
    "    y_pred_2 = model2.predict(X_test)\n",
    "    real_and_predict_2 = pd.DataFrame(zip(y_test.values, y_pred_2), columns = ['real', 'predict'])\n",
    "    model2_grade = metric2(real_and_predict_2)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    real_and_predict = pd.DataFrame(zip(y_test.values, y_pred), columns = ['real', 'predict'])\n",
    "    model_grade = metric2(real_and_predict)\n",
    "    \n",
    "    print(model2_grade, model_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q14 - Philosopical question, in Q13 did you include the split in the loop, is it good to do so?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('../input/pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 2 includes mesurments of Pima indian people at a beggining of a reaserch and an indication of being diagnosed with diabetes in the 5 years following.\n",
    "\n",
    "these are the columns descriptins:\n",
    "\n",
    "1. Number of times pregnant.\n",
    "\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
    "3. Diastolic blood pressure (mm Hg).\n",
    "4. Triceps skinfold thickness (mm).\n",
    "5. 2-Hour serum insulin (mu U/ml).\n",
    "6. Body mass index (weight in kg/(height in m)^2).\n",
    "7. Diabetes pedigree function.\n",
    "8. Age (years).\n",
    "9. Class variable (0 or 1).\n",
    "\n",
    "the task is to predict whether or not they will be diagnosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 - for the prediction, do you need a classifier or a regressor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 - choose a prediction model and initilize it (don't forget to import it)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 - in order to have testable results we need a test set, create one (import tools if you need them):\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.630208\n",
       " 1    0.369792\n",
       " Name: target, dtype: float64,\n",
       " 0    0.713542\n",
       " 1    0.286458\n",
       " Name: target, dtype: float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 check if your train and test sets are balanced, if you feel there not, create new, balanced sets\n",
    "train['target'].value_counts(normalize=True), test['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5 - look at the data and find the prediction target, create a feature df as well:\n",
    "y_train = train['target']\n",
    "y_test = test['target']\n",
    "X_train = train[[x for x in data2.columns if x!='target']]\n",
    "X_test = test[[x for x in data2.columns if x!='target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6 - fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 - predict using the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     real  predict\n",
       "0       0        1\n",
       "1       0        0\n",
       "2       0        0\n",
       "3       1        1\n",
       "4       1        1\n",
       "..    ...      ...\n",
       "187     0        0\n",
       "188     0        0\n",
       "189     0        0\n",
       "190     0        0\n",
       "191     1        1\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8 - compare real and predict by showing it out and looking at it\n",
    "real_and_predict = pd.DataFrame(zip(y_test.values, y_pred), columns = ['real', 'predict'])\n",
    "real_and_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict    0   1\n",
       "real            \n",
       "0        117  20\n",
       "1         21  34"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8 - create a confusion matrix\n",
    "pd.crosstab(real_and_predict['real'], real_and_predict['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is 0.618 precision is 0.63\n"
     ]
    }
   ],
   "source": [
    "#Q9 - calculate the precision\n",
    "def recall_precision(real_and_predict):\n",
    "    t = real_and_predict[(real_and_predict['real']==1)&(real_and_predict['predict']==1)].shape[0]\n",
    "    fp = real_and_predict[(real_and_predict['real']==0)&(real_and_predict['predict']==1)].shape[0]\n",
    "    fn = real_and_predict[(real_and_predict['real']==1)&(real_and_predict['predict']==0)].shape[0]\n",
    "    print(f'recall is {np.round((t/(t+fn)),3)} precision is {np.round((t/(t+fp)),3)}')\n",
    "recall_precision(real_and_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10 - calculate the recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    1\n",
       "real      \n",
       "0      137\n",
       "1       55"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q11 - is there an easy way to get higher recall\n",
    "pd.crosstab(real_and_predict['real'], pd.Series([1]*real_and_predict.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12 - is there an easy way to get higher recall and precision\n",
    "#No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_and_predict['proba'] = [x[1] for x in model.predict_proba(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "recall is 0.964 precision is 0.353\n",
      "0.2\n",
      "recall is 0.891 precision is 0.419\n",
      "0.3\n",
      "recall is 0.818 precision is 0.489\n",
      "0.4\n",
      "recall is 0.691 precision is 0.543\n",
      "0.5\n",
      "recall is 0.618 precision is 0.63\n",
      "0.6\n",
      "recall is 0.455 precision is 0.676\n",
      "0.7\n",
      "recall is 0.327 precision is 0.75\n",
      "0.8\n",
      "recall is 0.2 precision is 0.786\n"
     ]
    }
   ],
   "source": [
    "#Q13 - is there a way to toggle the tradeoff between recall and precision\n",
    "real_and_predict['proba'] = [x[1] for x in model.predict_proba(X_test)]\n",
    "def recall_precision(real_and_predict):\n",
    "    t = real_and_predict[(real_and_predict['real']==1)&(real_and_predict['predict']==1)].shape[0]\n",
    "    fp = real_and_predict[(real_and_predict['real']==0)&(real_and_predict['predict']==1)].shape[0]\n",
    "    fn = real_and_predict[(real_and_predict['real']==1)&(real_and_predict['predict']==0)].shape[0]\n",
    "    print(f'recall is {np.round((t/(t+fn)),3)} precision is {np.round((t/(t+fp)),3)}')\n",
    "\n",
    "for th in [x/10 for x in range(1,9)]:\n",
    "    print(th)\n",
    "    real_and_predict['predict'] = [1 if x>th else 0 for x in real_and_predict['proba']]\n",
    "    recall_precision(real_and_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
